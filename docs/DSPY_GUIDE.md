# Gu√≠a de Aprendizaje: DSPy Optimizers

Esta gu√≠a explica qu√© son los DSPy Optimizers, por qu√© son fundamentales para "programar" LLMs en lugar de solo promptearlos, y c√≥mo implementarlos en tu proyecto.

---

## 1. ¬øQu√© es un DSPy Optimizer?

Un **Optimizer** (antes llamado "Teleprompter") es un algoritmo que **mejora autom√°ticamente** tu programa DSPy.

En el paradigma tradicional de LLM, t√∫ escribes el prompt manualmente, lo pruebas, lo corriges, y repites ("Prompt Engineering"). En DSPy, t√∫ defines la **l√≥gica** (M√≥dulos) y la **calidad deseada** (M√©tricas), y el Optimizer se encarga de "compilar" el prompt perfecto para ti.

### ¬øQu√© optimiza exactamente?
1. **Instrucciones**: Reescribe la descripci√≥n de la tarea para que el LLM la entienda mejor.
2. **Ejemplos (Few-Shot)**: Selecciona, genera y refina los mejores ejemplos para incluir en el prompt.
3. **Pesos (Fine-tuning)**: En casos avanzados, puede fine-tunear un modelo peque√±o (ej. Llama-3-8B) para que act√∫e como GPT-4.

---

## 2. Los 3 Pilares de la Optimizaci√≥n

Para ejecutar cualquier optimizer, necesitas tres cosas:

### A. El Programa (`dspy.Module`)
Tu c√≥digo actual. Por ejemplo, tu `OpportunityPipeline`.
```python
class MiPipeline(dspy.Module):
    def forward(self, message):
        # ... l√≥gica de an√°lisis ...
        return resultado
```

### B. La M√©trica (`Metric`)
Una funci√≥n que recibe la salida y `truth` (la verdad esperada) y devuelve un puntaje (num√©rico o booleano).
```python
def mi_metrica(example, pred, trace=None):
    # ¬øEl estado detectado (NEW_OPPORTUNITY) es correcto?
    return example.expected_state == pred.conversation_state.state
```

### C. El Dataset (`Trainset`)
Una lista de ejemplos (`dspy.Example`) para que el optimizer aprenda.
- **BootstrapFewShot**: Funciona bien con **10-20 ejemplos**.
- **MIPROv2**: Idealmente **50+ ejemplos** (aunque tiene modo "light").

---

## 3. Principales Optimizers (2024/2025)

DSPy tiene muchos, pero hoy en d√≠a solo necesitas conocer estos dos para el 95% de los casos:

### üåü 1. BootstrapFewShot (El "Caballito de Batalla")
**Ideal para:** Empezar. Pocos datos (10 ejemplos).
**C√≥mo funciona:**
1. Toma tus preguntas de entrenamiento.
2. Usa un "Teacher" (usualmente el mismo modelo potente) para generar respuestas.
3. Verifica si las respuestas pasan tu `M√©trica`.
4. Si pasan, guarda ese par (Pregunta + Respuesta Generada) como un "Demo" verificado.
5. Inyecta estos Demos probados en tu prompt final.

### üöÄ 2. MIPROv2 (Multiprompt Instruction Proposal Optimizer)
**Ideal para:** M√°ximo rendimiento. Optimizar pipeline completo.
**C√≥mo funciona:**
Es mucho m√°s inteligente. Usa Optimizaci√≥n Bayesiana para buscar la mejor combinaci√≥n de:
- **Instrucciones**: Reescribe tus `docstrings` y descripciones de campos.
- **Ejemplos**: Selecciona qu√© demos mostrar y en qu√© orden.
**Coste:** Requiere m√°s llamadas al LLM durante el entrenamiento, pero produce mejores resultados.

---

## 4. C√≥mo Implementar un Optimizer Paso a Paso

Aqu√≠ tienes un flujo de trabajo est√°ndar para tu proyecto `nexton`.

### Paso 1: Definir Datos de Entrenamiento
Crea un archivo `training_data.py`.
```python
import dspy

trainset = [
    dspy.Example(
        message="Hola, busco un Java Dev...",
        expected_state="NEW_OPPORTUNITY"
    ).with_inputs("message"),
    
    dspy.Example(
        message="Gracias por tu tiempo",
        expected_state="COURTESY_CLOSE"
    ).with_inputs("message"),
    # ... m√°s ejemplos
]
```

### Paso 2: Configurar y Ejecutar (BootstrapFewShot)
```python
from dspy.teleprompt import BootstrapFewShot
from app.dspy_modules.pipeline import OpportunityPipeline
from app.dspy_modules.training_data import trainset

# 1. Definir m√©trica
def validate_state(example, pred, trace=None):
    return example.expected_state == pred.conversation_state.state

# 2. Configurar Optimizer
optimizer = BootstrapFewShot(
    metric=validate_state,
    max_bootstrapped_demos=4,  # Cu√°ntos ejemplos inventados incluir en el prompt
    max_labeled_demos=4,       # Cu√°ntos ejemplos reales tuyos usar
)

# 3. Compilar (Aqu√≠ ocurre la magia ‚ú®)
# El optimizer ejecuta el pipeline, prueba variantes y aprende.
compiled_pipeline = optimizer.compile(OpportunityPipeline(), trainset=trainset)
```

### Paso 3: Guardar y Cargar
Una vez optimizado, guardas el resultado. Ya no necesitas re-entrenar cada vez.
```python
# Guardar
compiled_pipeline.save("app/dspy_modules/optimized_pipeline.json")

# Cargar en producci√≥n
pipeline_prod = OpportunityPipeline()
pipeline_prod.load("app/dspy_modules/optimized_pipeline.json")
```

---

## 5. Buenas Pr√°cticas ("The DSPy Zen")

1. **Empieza sin Optimizar (Zero-Shot)**: Aseg√∫rate que tus signatures y l√≥gica b√°sica funcionan bien "a secas" antes de optimizar.
2. **La M√©trica es el Jefe**: Si tu m√©trica es mala, la optimizaci√≥n ser√° mala. Dedica tiempo a definir qu√© es el "√©xito". Para generaci√≥n de texto (ResponseGenerator), usa m√©tricas LLM-as-a-Judge (usar otro LLM para puntuar).
3. **MIPROv2 es el Rey**: Si tienes presupuesto de tokens y ~50 ejemplos, usa MIPROv2. Es capaz de encontrar matices en las instrucciones que a ti se te pasar√≠an por alto.
4. **Itera sobre los Datos, no los Prompts**: Si el modelo falla, no cambies el prompt manual. A√±ade un ejemplo al `trainset` que cubra ese caso de fallo y re-compila. **Esto es DSPy.**

## Resumen para tu Caso de Uso (Nexton)

Dado que tienes m√≥dulos de clasificaci√≥n (`ConversationState`) y extracci√≥n (`MessageAnalyzer`), el plan ideal es:

1. Crear ~20 ejemplos manuales variados.
2. Usar **BootstrapFewShot** primero para asegurar que el formato de salida sea siempre perfecto.
3. Evaluar resultados.
4. Si quieres mejorar el tono de las respuestas (`ResponseGenerator`), pasar a MIPROv2 para que encuentre el "estilo" de instrucci√≥n perfecto.
